{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502a45fd-a331-465d-87ee-2ae0ae93406f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialSSL.Dataloader import FullImageDatasetConstructor\n",
    "from spatialSSL.Utils import split_dataset\n",
    "from spatialSSL.Training import train\n",
    "from spatialSSL.Models import GAT4\n",
    "from spatialSSL.Training import train_epoch\n",
    "from spatialSSL.Testing import test\n",
    "from spatialSSL.Dataset import InMemoryGraphDataset\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf611f7-0b7e-4f3a-8a13-921e171043e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fine tune\n",
    "import torch\n",
    "import zipfile\n",
    "\n",
    "# Define a function to load the data from the ZIP file\n",
    "def load_from_zip(zip_path, file_name):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        with zipf.open(file_name) as file:\n",
    "            return torch.load(file)\n",
    "\n",
    "# Load the pre_val_list for fine tuning\n",
    "pre_val_list = load_from_zip('./processed_data/pre_training_data_img6_r30_n1_random_01.zip', 'pre_val_list.pt')\n",
    "pre_train_list = load_from_zip('./processed_data/pre_training_data_img6_r30_n1_random_01.zip', 'pre_train_list.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a7db8e-4d0a-4aa1-84af-3e9137104394",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50541d4e-9b9f-47a2-9d6d-c77de4ffa052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "###################### Now for testing\n",
    "# Split the pre_val_list into 80% for tune_train and 20% for temporary validation/test\n",
    "tune_train, temp_val_test = train_test_split(pre_train_list, test_size=0.20, random_state=42)\n",
    "\n",
    "# Split the temporary validation/test into 50% for tune_val and 50% for tune_test\n",
    "tune_val, tune_test = train_test_split(pre_val_list, test_size=0.50, random_state=42)\n",
    "\n",
    "# Now, tune_train contains 80% of pre_val_list, tune_val contains 10%, and tune_test contains 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf6d3d0-978b-4d44-b14b-e5b7ff3ed4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load into dataloader \n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Create DataLoader objects for pre-training and pre-validation\n",
    "tune_train_loader = DataLoader(tune_train, batch_size=1, shuffle=True)\n",
    "tune_val_loader = DataLoader(tune_val, batch_size=1, shuffle=False)\n",
    "tune_test_loader = DataLoader(tune_test, batch_size=1, shuffle=False)\n",
    "# Now you can use pre_train_loader and pre_val_loader in your training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493cc330-2523-4277-8d9d-098236814ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pre-trained models\n",
    "\n",
    "PRE_TRAINED_MODEL_PATH = \"./models/img6_r30_n1_random_01_GAT4_0.001_weight.pt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create Identity class\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity,self).__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2de53c8c-df47-47a5-b4f7-1cc2417d51ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model and add our layers\n",
    "\n",
    "input_layer = 550\n",
    "hidden_1 = 256\n",
    "hidden_2 = 33\n",
    "out_layer = 550\n",
    "\n",
    "# Pretraining\n",
    "# Define the device\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu') #\"cpu\"\n",
    "\n",
    "def freeze_except_last(model, num_unfrozen_layers=1):\n",
    "    # Convert model parameters into a list\n",
    "    params = list(model.parameters())\n",
    "\n",
    "    # Freeze all parameters\n",
    "    for param in params:\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze the last 'num_unfrozen_layers' layers\n",
    "    for param in params[-num_unfrozen_layers:]:\n",
    "        param.requires_grad = True\n",
    "\n",
    "model = GAT4(input_layer, hidden_1,hidden_2, out_layer).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(PRE_TRAINED_MODEL_PATH))\n",
    "freeze_except_last(model, num_unfrozen_layers=1) # Unfreeze the last 2 layers\n",
    "\n",
    "# Training code\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fed7d9a8-2dae-490f-88b2-71bf62d1a1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define loss function and optimizer\n",
    "#criterion = nn.MSELoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 300\n",
    "patience = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac72db3c-e86b-4c8a-bb9d-9d3bf2c3eba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, train loss: 0.4793, train r2: 0.0945, train mse: 0.4787,  val loss: 0.5247, val r2: 0.0874, val mse: 0.5247, Time: 1.4150s\n",
      "Epoch 2/300, train loss: 0.4763, train r2: 0.0978, train mse: 0.4772,  val loss: 0.5240, val r2: 0.0889, val mse: 0.5244, Time: 0.8651s\n",
      "Epoch 3/300, train loss: 0.4738, train r2: 0.1032, train mse: 0.4758,  val loss: 0.5229, val r2: 0.0875, val mse: 0.5239, Time: 0.8251s\n",
      "Epoch 4/300, train loss: 0.4726, train r2: 0.1061, train mse: 0.4749,  val loss: 0.5224, val r2: 0.0897, val mse: 0.5235, Time: 0.8236s\n",
      "Epoch 5/300, train loss: 0.4718, train r2: 0.1087, train mse: 0.4741,  val loss: 0.5217, val r2: 0.0911, val mse: 0.5231, Time: 0.8551s\n",
      "Epoch 6/300, train loss: 0.4708, train r2: 0.1110, train mse: 0.4735,  val loss: 0.5210, val r2: 0.0924, val mse: 0.5228, Time: 0.8620s\n",
      "Epoch 7/300, train loss: 0.4704, train r2: 0.1129, train mse: 0.4729,  val loss: 0.5200, val r2: 0.0936, val mse: 0.5224, Time: 0.8434s\n",
      "Epoch 8/300, train loss: 0.4700, train r2: 0.1145, train mse: 0.4725,  val loss: 0.5199, val r2: 0.0947, val mse: 0.5221, Time: 2.0099s\n",
      "Epoch 9/300, train loss: 0.4691, train r2: 0.1159, train mse: 0.4721,  val loss: 0.5194, val r2: 0.0957, val mse: 0.5218, Time: 0.8468s\n",
      "Epoch 10/300, train loss: 0.4687, train r2: 0.1172, train mse: 0.4717,  val loss: 0.5192, val r2: 0.0966, val mse: 0.5215, Time: 0.8390s\n",
      "Epoch 11/300, train loss: 0.4683, train r2: 0.1184, train mse: 0.4713,  val loss: 0.5188, val r2: 0.0974, val mse: 0.5213, Time: 0.8743s\n",
      "Epoch 12/300, train loss: 0.4682, train r2: 0.1194, train mse: 0.4710,  val loss: 0.5188, val r2: 0.0981, val mse: 0.5211, Time: 0.8466s\n",
      "Epoch 13/300, train loss: 0.4680, train r2: 0.1203, train mse: 0.4707,  val loss: 0.5184, val r2: 0.0987, val mse: 0.5209, Time: 0.8409s\n",
      "Epoch 14/300, train loss: 0.4671, train r2: 0.1212, train mse: 0.4704,  val loss: 0.5182, val r2: 0.0993, val mse: 0.5207, Time: 0.8419s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model\u001b[38;5;241m=\u001b[39mmodel, train_loader\u001b[38;5;241m=\u001b[39mtune_train_loader, val_loader\u001b[38;5;241m=\u001b[39mtune_val_loader, criterion\u001b[38;5;241m=\u001b[39mcriterion, num_epochs\u001b[38;5;241m=\u001b[39m num_epochs, patience \u001b[38;5;241m=\u001b[39m patience, optimizer\u001b[38;5;241m=\u001b[39m optimizer,weight_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m ,model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/img6_r30_n1_random_01_GAT4_0.001_tuned_r30_n1_random_01_freeze_1_GAT4_0.001.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/work/test/spatial_atlas_ssl/spatialSSL/Training.py:127\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, criterion, num_epochs, patience, optimizer, model_path, gene_expression, weight_loss)\u001b[0m\n\u001b[1;32m    121\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    123\u001b[0m train_loss, train_r2, train_mse \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, optimizer, criterion, r2_metric_train,\n\u001b[1;32m    124\u001b[0m                                               mse_metric_train, gene_expression, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m                                               weight_loss\u001b[38;5;241m=\u001b[39mweight_loss)\n\u001b[0;32m--> 127\u001b[0m val_loss, val_r2, val_mse \u001b[38;5;241m=\u001b[39m train_epoch(model, val_loader, optimizer, criterion, r2_metric_val, mse_metric_val,\n\u001b[1;32m    128\u001b[0m                                         gene_expression, weight_loss\u001b[38;5;241m=\u001b[39mweight_loss, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# scheduler.step() # Decrease learning rate by scheduler\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n",
      "File \u001b[0;32m~/work/test/spatial_atlas_ssl/spatialSSL/Training.py:35\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion, r2_metric, mse_metric, gene_expression, training, weight_loss)\u001b[0m\n\u001b[1;32m     32\u001b[0m target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto_dense()[cell_mask]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# print(data.x.float().to_dense().shape)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto_dense() \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m~\u001b[39mcell_mask)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# print(input.shape)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mto(device), data\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model=model, train_loader=tune_train_loader, val_loader=tune_val_loader, criterion=criterion, num_epochs= num_epochs, patience = patience, optimizer= optimizer,weight_loss = False ,model_path = './models/img6_r30_n1_random_01_GAT4_0.001_tuned_r30_n1_random_01_freeze_1_GAT4_0.001.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ee92e-57bd-4dc5-a14e-5778a89b1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = model.load_state_dict(torch.load(PRE_TRAINED_MODEL_PATH))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
