{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f8b93-2900-4231-8e70-09e019e81109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import zipfile\n",
    "from spatialSSL.Models import *\n",
    "from spatialSSL.Dataloader import FullImageDatasetConstructor\n",
    "from spatialSSL.Utils import split_dataset,visualize_cell_type_accuracies\n",
    "from spatialSSL.Training import train,train_classification,test_classification\n",
    "from spatialSSL.Models import GAT4,Transferlearn\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b93f3-f1cb-4c7d-ba95-0fd6526eb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode book\n",
    "category_encoding = {\n",
    "    'Astro-Epen': 0,\n",
    "    'CB GABA': 1,\n",
    "    'CB Glut': 2,\n",
    "    'CGE GABA': 3,\n",
    "    'CNU GABA': 4,\n",
    "    'CNU-HYa GABA': 5,\n",
    "    'CNU-HYa Glut': 6,\n",
    "    'HY GABA': 7,\n",
    "    'HY Glut': 8,\n",
    "    'HY Gnrh1 Glut': 9,\n",
    "    'HY MM Glut': 10,\n",
    "    'IT-ET Glut': 11,\n",
    "    'Immune': 12,\n",
    "    'LQ': 13,\n",
    "    'LSX GABA': 14,\n",
    "    'MB Dopa': 15,\n",
    "    'MB GABA': 16,\n",
    "    'MB Glut': 17,\n",
    "    'MB-HB Sero': 18,\n",
    "    'MGE GABA': 19,\n",
    "    'MH-LH Glut': 20,\n",
    "    'MOB-CR Glut': 21,\n",
    "    'MOB-DG-IMN': 22,\n",
    "    'MY GABA': 23,\n",
    "    'MY Glut': 24,\n",
    "    'NP-CT-L6b Glut': 25,\n",
    "    'OEG': 26,\n",
    "    'Oligo': 27,\n",
    "    'P GABA': 28,\n",
    "    'P Glut': 29,\n",
    "    'Pineal Glut': 30,\n",
    "    'TH Glut': 31,\n",
    "    'Vascular': 32\n",
    "}\n",
    "import torch\n",
    "def convert_to_float32(data_list):\n",
    "    for data in data_list:\n",
    "        # Convert attributes to float32\n",
    "        data.x = data.x.to(dtype=torch.float32)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "def thousands(x, pos):\n",
    "    return f'{int(x)}k'\n",
    "\n",
    "formatter = FuncFormatter(thousands)\n",
    "\n",
    "def plot_histogram(graph_list, title, cell_num_path, cell_type_path):\n",
    "    # Extracting number of cells in x\n",
    "    num_cells = [data.x.size(0) / 1000 for data in graph_list] # Divide by 1000 to represent in k\n",
    "\n",
    "    # Plotting histogram for number of cells in x\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(num_cells, bins=30, edgecolor='black')\n",
    "    plt.title(f'Number of Cells in Images for {title}')\n",
    "    plt.xlabel('Number of Cells')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.yticks(np.arange(0, max(plt.yticks()[0]), 1)) # Set y-ticks to integer values\n",
    "    plt.gca().xaxis.set_major_formatter(formatter) # Apply the formatter\n",
    "    plt.savefig(cell_num_path) # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Extracting cell types\n",
    "    cell_types = [data.cell_type.tolist() for data in graph_list]\n",
    "    flat_cell_types = [item for sublist in cell_types for item in sublist]\n",
    "\n",
    "    # Get the encode_book from the first data object in the graph_list\n",
    "    encode_book = graph_list[0].encode_book\n",
    "\n",
    "    # Count the frequency of each cell type\n",
    "    cell_type_counts = Counter(flat_cell_types)\n",
    "\n",
    "    # Sort cell types by frequency\n",
    "    sorted_cell_types = sorted(cell_type_counts.items(), key=lambda x: x[1]/1000, reverse=True) # Divide by 1000 to represent in k\n",
    "    sorted_labels = [list(encode_book.keys())[cell_type[0]] for cell_type in sorted_cell_types] # Convert keys to list\n",
    "    sorted_values = [cell_type[1] for cell_type in sorted_cell_types]\n",
    "\n",
    "    # Plotting histogram for distribution of cell types\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.bar(range(len(sorted_values)), sorted_values, edgecolor='black')\n",
    "    plt.title(f'Distribution of Cell Types for {title}')\n",
    "    plt.xlabel('Cell Type')\n",
    "    plt.ylabel('Number of Cells')\n",
    "    plt.gca().yaxis.set_major_formatter(formatter) # Apply the formatter\n",
    "    plt.xticks(ticks=range(len(sorted_labels)), labels=sorted_labels, rotation=90)\n",
    "    plt.savefig(cell_type_path) # Save the plot\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "# Define a function to load the data from the ZIP file\n",
    "def load_from_zip(zip_path, file_name):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        with zipf.open(file_name) as file:\n",
    "            return torch.load(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PATHS\n",
    "DATA_PATH = \"./data/subset_6img_atlas_brain.h5ad\"\n",
    "PREPROCESSED_IMG_PATH = \"./processed_data/plots/\"\n",
    "PREPROCESSED_DATA_PATH = \"./processed_data/\"\n",
    "\n",
    "PREPROCESSED_DATA_ZIP_NAME = \"pre_training_data_img6_r30_n1_random_01.zip\"\n",
    "TUNE_DATA_ZIP_NAME = \"tune_data_img6_r30_n1_random_01.zip\"\n",
    "\n",
    "PRE_TRAIN_NCELL_IMG_NAME = \"pre_train_cell_num_img6_r30_n1_random_01.jpg\"\n",
    "PRE_TRAIN_CTYPE_IMG_NAME = \"pre_train_cell_type_img6_r30_n1_random_01.jpg\"\n",
    "\n",
    "PRE_VAL_NCELL_IMG_NAME = \"pre_val_cell_num_img6_r30_n1_random_01.jpg\"\n",
    "PRE_VAL_CTYPE_IMG_NAME = \"pre_val_cell_type_img6_r30_n1_random_01.jpg\"\n",
    "\n",
    "PRE_MODEL_STORE_PATH = \"./models/pretrained/img6_r30_n1_random_01_GAT4_0.001.pt\"\n",
    "TRANSFER_MODEL_STORE_PATH = \"./models/transfer/img6_r30_n1_random_01_GAT4_0.001_tf_GAT4_0.001.pt\"\n",
    "\n",
    "# Hyperparams\n",
    "\n",
    "# Graph construction\n",
    "image_col = \"section\"\n",
    "label_col = \"class_label\"\n",
    "radius = 30\n",
    "node_level = 1\n",
    "random_mask_percentage = 0.1\n",
    "mask_method = \"random\"\n",
    "niche_to_mask = 1\n",
    "celltype_to_mask = \"LQ\"\n",
    "\n",
    "# Pre-train Model\n",
    "in_channels  = 550\n",
    "hidden_channels_1 = 256\n",
    "hidden_channels_2 = 33\n",
    "out_channels= 550\n",
    "lr = 0.001\n",
    "num_epochs = 300\n",
    "patience = 8\n",
    "weight_loss = False\n",
    "\n",
    "# Transfer learning\n",
    "num_classes = 33\n",
    "freeze = False\n",
    "lr_transfer = 0.001\n",
    "num_epochs_transfer = 300"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9b8f99a42b8a1be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded283dc-7554-4bb9-8789-bf9cb1719a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Full_image_dataloader\n",
    "\n",
    "data_constracter = FullImageDatasetConstructor(file_path=DATA_PATH,\n",
    "                                        image_col= image_col,\n",
    "                                        label_col=label_col,\n",
    "                                        radius=radius,\n",
    "                                        node_level = node_level,\n",
    "                                               mask_method= mask_method,\n",
    "                                       random_mask_percentage = random_mask_percentage,\n",
    "                                        encode_book = category_encoding,\n",
    "                                       niche_to_mask = niche_to_mask,\n",
    "                                       celltype_to_mask = celltype_to_mask,\n",
    "                                               )\n",
    "# Load the data\n",
    "data_constracter.load_data()\n",
    "# Construct the graph\n",
    "graph_list = data_constracter.construct_graph()\n",
    "graph_list = convert_to_float32(graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70a791-8278-4dc3-8289-f04838bd486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the graph_list into 80% for pre-training and 20% for pre-training validation\n",
    "pre_train_list, pre_val_list = train_test_split(graph_list, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607a589-0208-49dc-9349-cde4dba947ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for pre_train_list and pre_val_list\n",
    "plot_histogram(pre_train_list, 'Pre-Train', PREPROCESSED_IMG_PATH + PRE_TRAIN_NCELL_IMG_NAME, PREPROCESSED_IMG_PATH+ PRE_TRAIN_CTYPE_IMG_NAME)\n",
    "plot_histogram(pre_val_list, 'Pre-Validation', PREPROCESSED_IMG_PATH + PRE_VAL_NCELL_IMG_NAME, PREPROCESSED_IMG_PATH+ PRE_VAL_CTYPE_IMG_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8070e4f-7df5-46b0-b449-4e0bead45ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Save train_loader and val_loader to pickle files\n",
    "torch.save(pre_train_list, PREPROCESSED_DATA_PATH+\"pre_train_list.pt\")\n",
    "torch.save(pre_val_list, PREPROCESSED_DATA_PATH+'pre_val_list.pt')\n",
    "\n",
    "# Create a ZIP file and add the pickle files to it\n",
    "with zipfile.ZipFile(PREPROCESSED_DATA_PATH+PREPROCESSED_DATA_ZIP_NAME, 'w') as zipf:\n",
    "    zipf.write(PREPROCESSED_DATA_PATH+'pre_train_list.pt', arcname='pre_train_list.pt')\n",
    "    zipf.write(PREPROCESSED_DATA_PATH+'pre_val_list.pt', arcname='pre_val_list.pt')\n",
    "\n",
    "# Delete the torch files\n",
    "os.remove(PREPROCESSED_DATA_PATH+'pre_train_list.pt')\n",
    "os.remove(PREPROCESSED_DATA_PATH+'pre_val_list.pt')\n",
    "\n",
    "print(\"ZIP file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33fc2e1-032c-4328-aa20-42f468f43529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre_train_list and pre_val_list from the ZIP file\n",
    "pre_train_list = load_from_zip(PREPROCESSED_DATA_PATH+PREPROCESSED_DATA_ZIP_NAME, 'pre_train_list.pt')\n",
    "pre_val_list = load_from_zip(PREPROCESSED_DATA_PATH+PREPROCESSED_DATA_ZIP_NAME, 'pre_val_list.pt')\n",
    "\n",
    "# Create DataLoader objects for pre-training and pre-validation\n",
    "pre_train_loader = DataLoader(pre_train_list, batch_size=1, shuffle=True)\n",
    "pre_val_loader = DataLoader(pre_val_list, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5c2a9-8665-4215-840c-318e6c4f63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pretraining\n",
    "\n",
    "\n",
    "\n",
    "# Pretraining\n",
    "# Define the device\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu') #\"cpu\"\n",
    "\n",
    "# Create the model\n",
    "model = GAT4(in_channels, hidden_channels_1,hidden_channels_2, out_channels).to(device) # in_channels is set to 100 as an example. Please replace it with your actual feature size.\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "train(model=model, train_loader=pre_train_loader, val_loader=pre_val_loader, criterion=criterion, num_epochs= num_epochs, patience = patience, optimizer= optimizer,weight_loss = weight_loss, model_path=PRE_MODEL_STORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffeb14-8110-4fa8-91dd-5c458756ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the pre_val_list into 80% for tune_train and 20% for temporary validation/test\n",
    "tune_train, temp_val_test = train_test_split(pre_train_list, test_size=0.20, random_state=42)\n",
    "\n",
    "# Split the temporary validation/test into 50% for tune_val and 50% for tune_test\n",
    "tune_val, tune_test = train_test_split(temp_val_test, test_size=0.50, random_state=42)\n",
    "\n",
    "# save the tune_train, tune_val and tune_test to pt files\n",
    "torch.save(tune_train, PREPROCESSED_DATA_PATH+\"tune_train.pt\")\n",
    "torch.save(tune_val, PREPROCESSED_DATA_PATH+'tune_val.pt')\n",
    "torch.save(tune_test, PREPROCESSED_DATA_PATH+'tune_test.pt')\n",
    "\n",
    "# Create a ZIP file and add the pickle files to it\n",
    "with zipfile.ZipFile(PREPROCESSED_DATA_PATH+PREPROCESSED_DATA_ZIP_NAME, 'w') as zipf:\n",
    "    zipf.write(PREPROCESSED_DATA_PATH+'tune_train.pt', arcname='tune_train.pt')\n",
    "    zipf.write(PREPROCESSED_DATA_PATH+'tune_val.pt', arcname='tune_val.pt')\n",
    "    zipf.write(PREPROCESSED_DATA_PATH+'tune_test.pt', arcname='tune_test.pt')\n",
    "    \n",
    "# Delete the torch files\n",
    "os.remove(PREPROCESSED_DATA_PATH+'tune_train.pt')\n",
    "os.remove(PREPROCESSED_DATA_PATH+'tune_val.pt')\n",
    "os.remove(PREPROCESSED_DATA_PATH+'tune_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcf906-e772-4b44-b261-94798bf9a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects for pre-training and pre-validation\n",
    "tune_train_loader = DataLoader(tune_train, batch_size=1, shuffle=True)\n",
    "tune_val_loader = DataLoader(tune_val, batch_size=1, shuffle=False)\n",
    "tune_test_loader = DataLoader(tune_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba48783-db80-4c89-a8a7-01b552489e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu') #\"cpu\"\n",
    "pretrained_model = GAT4(in_channels, hidden_channels_1,hidden_channels_2, out_channels)\n",
    "\n",
    "if freeze:\n",
    "    for param in pretrained_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "model = Transferlearn(pretrained_model,out_channels,hidden_channels_1,num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9fb1c-8cf8-4f57-9e77-ebf3bbb9b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_transfer)\n",
    "\n",
    "train_classification(model=model, train_loader=tune_train_loader, val_loader=tune_val_loader, num_epochs=num_epochs_transfer,criterion=criterion, num_classes=num_classes,optimizer=optimizer,model_path=TRANSFER_MODEL_STORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4f203-5794-4c42-828e-0be0ed01ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "cell_type_accuracies = test_classification(model, tune_test_loader, criterion, num_classes)\n",
    "visualize_cell_type_accuracies(cell_type_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
