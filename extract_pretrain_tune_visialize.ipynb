{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f8b93-2900-4231-8e70-09e019e81109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialSSL.Dataloader import FullImageDatasetConstructor\n",
    "from spatialSSL.Utils import split_dataset\n",
    "from spatialSSL.Training import train\n",
    "\n",
    "from spatialSSL.Training import train_epoch\n",
    "from spatialSSL.Testing import test\n",
    "from spatialSSL.Dataset import InMemoryGraphDataset\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import zipfile\n",
    "import torch\n",
    "from spatialSSL.Dataloader import FullImageDatasetConstructor\n",
    "from spatialSSL.Utils import split_dataset\n",
    "from spatialSSL.Training import train, train_classification\n",
    "from spatialSSL.Models import *\n",
    "from spatialSSL.Training import train_epoch\n",
    "from spatialSSL.Testing import test\n",
    "from spatialSSL.Dataset import InMemoryGraphDataset\n",
    "import numpy as np\n",
    "from spatialSSL.Dataloader import FullImageDatasetConstructor\n",
    "from spatialSSL.Utils import split_dataset,visualize_cell_type_accuracies\n",
    "from spatialSSL.Training import train,train_classification,test_classification\n",
    "from spatialSSL.Models import GAT4,Transferlearn\n",
    "from spatialSSL.Training import train_epoch\n",
    "from spatialSSL.Testing import test\n",
    "from spatialSSL.Dataset import InMemoryGraphDataset\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b93f3-f1cb-4c7d-ba95-0fd6526eb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode book\n",
    "category_encoding = {\n",
    "    'Astro-Epen': 0,\n",
    "    'CB GABA': 1,\n",
    "    'CB Glut': 2,\n",
    "    'CGE GABA': 3,\n",
    "    'CNU GABA': 4,\n",
    "    'CNU-HYa GABA': 5,\n",
    "    'CNU-HYa Glut': 6,\n",
    "    'HY GABA': 7,\n",
    "    'HY Glut': 8,\n",
    "    'HY Gnrh1 Glut': 9,\n",
    "    'HY MM Glut': 10,\n",
    "    'IT-ET Glut': 11,\n",
    "    'Immune': 12,\n",
    "    'LQ': 13,\n",
    "    'LSX GABA': 14,\n",
    "    'MB Dopa': 15,\n",
    "    'MB GABA': 16,\n",
    "    'MB Glut': 17,\n",
    "    'MB-HB Sero': 18,\n",
    "    'MGE GABA': 19,\n",
    "    'MH-LH Glut': 20,\n",
    "    'MOB-CR Glut': 21,\n",
    "    'MOB-DG-IMN': 22,\n",
    "    'MY GABA': 23,\n",
    "    'MY Glut': 24,\n",
    "    'NP-CT-L6b Glut': 25,\n",
    "    'OEG': 26,\n",
    "    'Oligo': 27,\n",
    "    'P GABA': 28,\n",
    "    'P Glut': 29,\n",
    "    'Pineal Glut': 30,\n",
    "    'TH Glut': 31,\n",
    "    'Vascular': 32\n",
    "}\n",
    "import torch\n",
    "def convert_to_float32(data_list):\n",
    "    for data in data_list:\n",
    "        # Convert attributes to float32\n",
    "        data.x = data.x.to(dtype=torch.float32)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "def thousands(x, pos):\n",
    "    return f'{int(x)}k'\n",
    "\n",
    "formatter = FuncFormatter(thousands)\n",
    "\n",
    "def plot_histogram(graph_list, title, cell_num_path, cell_type_path):\n",
    "    # Extracting number of cells in x\n",
    "    num_cells = [data.x.size(0) / 1000 for data in graph_list] # Divide by 1000 to represent in k\n",
    "\n",
    "    # Plotting histogram for number of cells in x\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(num_cells, bins=30, edgecolor='black')\n",
    "    plt.title(f'Number of Cells in Images for {title}')\n",
    "    plt.xlabel('Number of Cells')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.yticks(np.arange(0, max(plt.yticks()[0]), 1)) # Set y-ticks to integer values\n",
    "    plt.gca().xaxis.set_major_formatter(formatter) # Apply the formatter\n",
    "    plt.savefig(cell_num_path) # Save the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Extracting cell types\n",
    "    cell_types = [data.cell_type.tolist() for data in graph_list]\n",
    "    flat_cell_types = [item for sublist in cell_types for item in sublist]\n",
    "\n",
    "    # Get the encode_book from the first data object in the graph_list\n",
    "    encode_book = graph_list[0].encode_book\n",
    "\n",
    "    # Count the frequency of each cell type\n",
    "    cell_type_counts = Counter(flat_cell_types)\n",
    "\n",
    "    # Sort cell types by frequency\n",
    "    sorted_cell_types = sorted(cell_type_counts.items(), key=lambda x: x[1]/1000, reverse=True) # Divide by 1000 to represent in k\n",
    "    sorted_labels = [list(encode_book.keys())[cell_type[0]] for cell_type in sorted_cell_types] # Convert keys to list\n",
    "    sorted_values = [cell_type[1] for cell_type in sorted_cell_types]\n",
    "\n",
    "    # Plotting histogram for distribution of cell types\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.bar(range(len(sorted_values)), sorted_values, edgecolor='black')\n",
    "    plt.title(f'Distribution of Cell Types for {title}')\n",
    "    plt.xlabel('Cell Type')\n",
    "    plt.ylabel('Number of Cells')\n",
    "    plt.gca().yaxis.set_major_formatter(formatter) # Apply the formatter\n",
    "    plt.xticks(ticks=range(len(sorted_labels)), labels=sorted_labels, rotation=90)\n",
    "    plt.savefig(cell_type_path) # Save the plot\n",
    "    plt.show()\n",
    "    \n",
    "def save_to_zip(loader, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(loader, f)\n",
    "        \n",
    "# Define a function to load the data from the ZIP file\n",
    "def load_from_zip(zip_path, file_name):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "        with zipf.open(file_name) as file:\n",
    "            return torch.load(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded283dc-7554-4bb9-8789-bf9cb1719a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Full_image_dataloader\n",
    "\n",
    " \n",
    "#file_path = \"./data/img_119670929.h5ad\"\n",
    "file_path = \"./data/subset_6img_atlas_brain.h5ad\"\n",
    "#file_path = \"./data/atlas_brain_638850_CCF.h5ad\"\n",
    "#file_path = \"./data/sub_20img_adata.h5ad\"\n",
    "\n",
    "data_constracter = FullImageDatasetConstructor(file_path=file_path,\n",
    "                                        image_col=\"section\",\n",
    "                                        label_col=\"class_label\",\n",
    "                                        include_label=False,\n",
    "                                        radius=30,\n",
    "                                        node_level = 1,\n",
    "                                       random_mask_percentage = 0.1,\n",
    "                                        encode_book = category_encoding\n",
    "                                       #    niche_to_mask = 100\n",
    "                                       #celltype_to_mask = \"LQ\"\n",
    "                                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e22c3b-fe34-4d20-b37a-85ca897718e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_constracter.load_data()\n",
    "# Construct the graph\n",
    "graph_list = data_constracter.construct_graph()\n",
    "graph_list = convert_to_float32(graph_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70a791-8278-4dc3-8289-f04838bd486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the graph_list into 80% for pre-training and 20% for pre-training validation\n",
    "pre_train_list, pre_val_list = train_test_split(graph_list, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607a589-0208-49dc-9349-cde4dba947ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for pre_train_list and pre_val_list\n",
    "plot_histogram(pre_train_list, 'Pre-Train', './processed_data/plots/pre_train_cell_num_img6_r30_n1_random_01.jpg', './processed_data/plots/pre_train_cell_type_img6_r30_n1_random_01.jpg')\n",
    "plot_histogram(pre_val_list, 'Pre-Validation', './processed_data/plots/pre_val_cell_num_img6_r30_n1_random_01.jpg', './processed_data/plots/pre_val_cell_type_img6_r30_n1_random_01.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8070e4f-7df5-46b0-b449-4e0bead45ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train_loader and val_loader to pickle files\n",
    "torch.save(pre_train_list, './processed_data/pre_train_list.pt')\n",
    "torch.save(pre_val_list, './processed_data/pre_val_list.pt')\n",
    "\n",
    "# Create a ZIP file and add the pickle files to it\n",
    "with zipfile.ZipFile('./processed_data/pre_training_data_img6_r30_n1_random_01.zip', 'w') as zipf:\n",
    "    zipf.write('./processed_data/pre_train_list.pt', arcname='pre_train_list.pt')\n",
    "    zipf.write('./processed_data/pre_val_list.pt', arcname='pre_val_list.pt')\n",
    "\n",
    "print(\"ZIP file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33fc2e1-032c-4328-aa20-42f468f43529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre_train_list and pre_val_list from the ZIP file\n",
    "pre_train_list = load_from_zip('./processed_data/pre_training_data_img6_r30_n1_random_01.zip', 'pre_train_list.pt')\n",
    "pre_val_list = load_from_zip('./processed_data/pre_training_data_img6_r30_n1_random_01.zip', 'pre_val_list.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d27b78-2703-4c90-a181-11ebb4b243a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects for pre-training and pre-validation\n",
    "pre_train_loader = DataLoader(pre_train_list, batch_size=1, shuffle=True)\n",
    "pre_val_loader = DataLoader(pre_val_list, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5c2a9-8665-4215-840c-318e6c4f63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pretraining\n",
    "\n",
    "in_channels  = 550\n",
    "hidden_channels_1 = 256\n",
    "hidden_channels_2 = 33\n",
    "out_channels= 550\n",
    "\n",
    "# Pretraining\n",
    "# Define the device\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu') #\"cpu\"\n",
    "\n",
    "# Create the model\n",
    "model = GAT4(in_channels, hidden_channels_1,hidden_channels_2, out_channels).to(device) # in_channels is set to 100 as an example. Please replace it with your actual feature size.\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 300\n",
    "patience = 8\n",
    "\n",
    "train(model=model, train_loader=pre_train_loader, val_loader=pre_val_loader, criterion=criterion, num_epochs= num_epochs, patience = patience, optimizer= optimizer,weight_loss = False, model_path=\"./models/img6_r30_n1_random_01_GAT4_0.001.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffeb14-8110-4fa8-91dd-5c458756ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the pre_val_list into 80% for tune_train and 20% for temporary validation/test\n",
    "tune_train, temp_val_test = train_test_split(pre_train_list, test_size=0.20, random_state=42)\n",
    "\n",
    "# Split the temporary validation/test into 50% for tune_val and 50% for tune_test\n",
    "tune_val, tune_test = train_test_split(temp_val_test, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcf906-e772-4b44-b261-94798bf9a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects for pre-training and pre-validation\n",
    "tune_train_loader = DataLoader(tune_train, batch_size=1, shuffle=True)\n",
    "tune_val_loader = DataLoader(tune_val, batch_size=1, shuffle=False)\n",
    "tune_test_loader = DataLoader(tune_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339409b-7883-41e0-adc3-01709912e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_PATH = \"./models/img6_r30_n1_random_01_GAT4_0.001_weight.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba48783-db80-4c89-a8a7-01b552489e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "\n",
    "num_classes = 33\n",
    "in_channels  = 550\n",
    "hidden_channels_1 = 256\n",
    "hidden_channels_2 = 33\n",
    "out_channels= 550\n",
    "\n",
    "freeze = True\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu') #\"cpu\"\n",
    "pretrained_model = GAT4(in_channels, hidden_channels_1,hidden_channels_2, out_channels)\n",
    "\n",
    "if freeze:\n",
    "    for param in pretrained_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "model = Transferlearn(pretrained_model,out_channels,hidden_channels_1,num_classes).to(device)\n",
    "model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9fb1c-8cf8-4f57-9e77-ebf3bbb9b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_classification(model=model, train_loader=tune_train_loader, val_loader=tune_val_loader, num_epochs=10,criterion=criterion, num_classes=num_classes,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4f203-5794-4c42-828e-0be0ed01ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "cell_type_accuracies = test_classification(model, tune_test_loader, criterion, num_classes)\n",
    "visualize_cell_type_accuracies(cell_type_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade9916-ada1-4203-8eb6-12f709dba1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0d632-159f-4d96-bbc6-eec463c8435c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0bee49-3d03-4120-9a03-434701c1e528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631575e-978e-4cd2-9857-aa6cd8c897a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0801480-5d72-4f5b-bd16-6eef21ce1291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b3833-2732-4601-b453-313a0d32bf40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
