{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lg\\anaconda3\\envs\\spatial_atlas_ssl\\lib\\site-packages\\geopandas\\_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lg\\anaconda3\\envs\\spatial_atlas_ssl\\lib\\site-packages\\spatialdata\\__init__.py:9: UserWarning: Geopandas was set to use PyGEOS, changing to shapely 2.0 with:\n",
      "\n",
      "\tgeopandas.options.use_pygeos = True\n",
      "\n",
      "If you intended to use PyGEOS, set the option to False.\n",
      "  _check_geopandas_using_shapely()\n"
     ]
    }
   ],
   "source": [
    "from spatialSSL.Dataloader import EgoNetDataloader, FullImageConstracter\n",
    "from spatialSSL.Utils import split_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Create an instance of Full_image_dataloader\n",
    "\n",
    "#file_path = \"./data/img_119670929.h5ad\"\n",
    "file_path = \"./data/subset_6img_atlas_brain.h5ad\"\n",
    "data_constracter = FullImageConstracter(file_path=file_path, image_col=\"section\", label_col=\"class_id_label\", include_label=False, radius=20,node_level = 1, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Constructing Graphs:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e535fe5599b444fbfd00bf986464646"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "data_constracter.load_data()\n",
    "\n",
    "# Construct the graph\n",
    "graph_list = data_constracter.construct_graph()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[26230, 550], edge_index=[2, 102942], y=[2623, 550], mask=[26230], cell_type=['22 MY GABA', '22 MY GABA', '22 MY GABA', '22 MY GABA', '22 MY GABA', ..., '31 Vascular', '31 Vascular', '31 Vascular', '31 Vascular', '31 Vascular']\n",
      "Length: 26230\n",
      "Categories (15, object): ['11 HY GABA', '15 HY Glut', '17 P Glut', '18 MB-HB Sero', ..., '30 OEG', '31 Vascular', '32 Immune', '33 LQ'], cell_type_masked=['24 CB GABA', '28 Astro-Epen', '31 Vascular', '29 Oligo', '28 Astro-Epen', ..., '29 Oligo', '25 CB Glut', '31 Vascular', '25 CB Glut', '25 CB Glut']\n",
      "Length: 2623\n",
      "Categories (15, object): ['11 HY GABA', '15 HY Glut', '17 P Glut', '18 MB-HB Sero', ..., '30 OEG', '31 Vascular', '32 Immune', '33 LQ'], image='1199650929')\n"
     ]
    }
   ],
   "source": [
    "for x in graph_list:\n",
    "    print(x)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_loader, test_loader, val_loader = split_dataset(graph_list,split_percent=(0.6, 0.2, 0.2), batch_size=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5089\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    print(list(x.mask).count(False))\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4\n",
      "Validation size: 1\n",
      "Test size: 1\n"
     ]
    }
   ],
   "source": [
    "# Print out the size of each set to verify\n",
    "print(f\"Train size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation size: {len(val_loader.dataset)}\")\n",
    "print(f\"Test size: {len(test_loader.dataset)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from torch import nn, optim, Tensor\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.linear = nn.Linear(out_channels, 550)\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        x = self.act(self.conv1(x, edge_index))\n",
    "        x = self.act(self.conv2(x, edge_index))\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create the model\n",
    "model = GCN(550, 550, 550).to(device) # in_channels is set to 100 as an example. Please replace it with your actual feature size.\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1) # learning rate scheduler\n",
    "\n",
    "num_epochs = 50\n",
    "patience = 5\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data.x.float(), data.edge_index.long())\n",
    "        loss = criterion(outputs[~data.mask], data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        targets_list.append(data.y.cpu().detach())\n",
    "        outputs_list.append(outputs[~data.mask].cpu().detach())\n",
    "\n",
    "    return total_loss / len(loader.dataset), r2_score(torch.cat(targets_list).numpy(), torch.cat(outputs_list).numpy())\n",
    "\n",
    "def validate_one_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data.x.float(), data.edge_index.long())\n",
    "            loss = criterion(outputs[~data.mask], data.y.float())\n",
    "\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            targets_list.append(data.y.cpu())\n",
    "            outputs_list.append(outputs[~data.mask].cpu())\n",
    "\n",
    "    return total_loss / len(loader.dataset), r2_score(torch.cat(targets_list).numpy(), torch.cat(outputs_list).numpy())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5089, 550])\n",
      "torch.Size([5089, 550])\n",
      "torch.Size([2623, 550])\n",
      "torch.Size([2623, 550])\n",
      "torch.Size([3604, 550])\n",
      "torch.Size([3604, 550])\n",
      "torch.Size([5101, 550])\n",
      "torch.Size([5101, 550])\n",
      "Epoch 1/50, train loss: 0.0106, train r2: 0.0000,  val loss: 0.0016, val r2: 0.0000, Time: 11.378904581069946s\n",
      "torch.Size([5089, 550])\n",
      "torch.Size([5089, 550])\n",
      "torch.Size([2623, 550])\n",
      "torch.Size([2623, 550])\n",
      "torch.Size([3604, 550])\n",
      "torch.Size([3604, 550])\n",
      "torch.Size([5101, 550])\n",
      "torch.Size([5101, 550])\n",
      "Epoch 2/50, train loss: 0.0010, train r2: 0.0000,  val loss: 0.0006, val r2: 0.0000, Time: 11.496379375457764s\n",
      "torch.Size([5089, 550])\n",
      "torch.Size([5089, 550])\n",
      "torch.Size([2623, 550])\n",
      "torch.Size([2623, 550])\n",
      "torch.Size([3604, 550])\n",
      "torch.Size([3604, 550])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m      7\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 8\u001B[0m     train_loss, train_r2 \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     val_loss, val_r2 \u001B[38;5;241m=\u001B[39m validate_one_epoch(model, val_loader, criterion)\n\u001B[0;32m     10\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep() \u001B[38;5;66;03m# Decrease learning rate by scheduler\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[8], line 50\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, loader, optimizer, criterion)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28mprint\u001B[39m(data\u001B[38;5;241m.\u001B[39my\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     49\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs[\u001B[38;5;241m~\u001B[39mdata\u001B[38;5;241m.\u001B[39mmask], data\u001B[38;5;241m.\u001B[39my\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[1;32m---> 50\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     53\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m data\u001B[38;5;241m.\u001B[39mnum_graphs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\spatial_atlas_ssl\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\spatial_atlas_ssl\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_r2 = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_r2 = validate_one_epoch(model, val_loader, criterion)\n",
    "    scheduler.step() # Decrease learning rate by scheduler\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f}, train r2: {train_r2:.4f},  val loss: {val_loss:.4f}, val r2: {val_r2:.4f}, Time: {time.time()-start_time}s\")\n",
    "\n",
    "print(f\"Best val loss: {best_val_loss:.4f}, at epoch {best_epoch+1}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
