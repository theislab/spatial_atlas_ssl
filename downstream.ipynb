{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c45ca33-ed80-4274-b090-01996bb4fab0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ouga/home/ag_gagneur/liaoc/.conda/envs/ml_genetic/lib/python3.11/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/data/ouga/home/ag_gagneur/liaoc/.conda/envs/ml_genetic/lib/python3.11/site-packages/spatialdata/__init__.py:9: UserWarning: Geopandas was set to use PyGEOS, changing to shapely 2.0 with:\n",
      "\n",
      "\tgeopandas.options.use_pygeos = True\n",
      "\n",
      "If you intended to use PyGEOS, set the option to False.\n",
      "  _check_geopandas_using_shapely()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from spatialSSL.Dataloader import FullImageDatasetConstructor\n",
    "from spatialSSL.Utils import split_dataset\n",
    "from spatialSSL.Training import train\n",
    "from spatialSSL.Training import train_epoch\n",
    "from spatialSSL.Testing import test\n",
    "from spatialSSL.Dataset import InMemoryGraphDataset\n",
    "from torch import nn, optim, Tensor\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv,GATConv\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.nn import LeakyReLU, Dropout\n",
    "import time\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9723130-6410-4bc7-9355-92f00fc17899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1de8d1-37aa-4e36-a03f-d55cdadc2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedGAT_2(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        \n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        x = self.dropout(self.act(self.conv1(x, edge_index)))\n",
    "        x = checkpoint(self.conv2, x, edge_index)\n",
    "        x = self.act(self.conv3(x, edge_index))  # Typically, dropout is not applied to the final layer.\n",
    "        return x\n",
    "    \n",
    "class GAT_2(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_label, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.lin1 = nn.Linear(hidden_channels, num_label)  # Use num_label instead of 20\n",
    "        self.act = nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        x = self.dropout(self.act(self.conv1(x, edge_index)))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.lin1(x)\n",
    "        #x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1584afc2-d47c-4c8d-acb4-009b160e6eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PretrainedGAT_2(\n",
       "  (conv1): GATConv(550, 550, heads=1)\n",
       "  (conv2): GATConv(550, 550, heads=1)\n",
       "  (conv3): GATConv(550, 550, heads=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (act): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_path = \"./models/model_fillomgGAT2.pt\"\n",
    "\n",
    "# Load the pretrained model without the linear layer\n",
    "pretrained_model = PretrainedGAT_2(550, 550, 550).to(device)\n",
    "pretrained_model.load_state_dict(torch.load(model_path))\n",
    "pretrained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5e3c2b-4eb6-4b47-9aaa-4198e1607a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the weights from the pretrained model to the new model with the linear layer\n",
    "model = GAT_2(550, 550, 550, 24).to(device)\n",
    "model.conv1.load_state_dict(pretrained_model.conv1.state_dict())\n",
    "#model.conv2.load_state_dict(pretrained_model.conv2.state_dict())\n",
    "model.conv3.load_state_dict(pretrained_model.conv3.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496183d5-205b-47bc-a2f2-ac47042529e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c0901a322c4996aa06a64ff71501af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing Graphs:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = \"./data/subset_6img_atlas_brain.h5ad\"\n",
    "\n",
    "# Create the dataloader\n",
    "dataset_constructor = FullImageDatasetConstructor(file_path=file_path, image_col=\"section\",\n",
    "                                                                     label_col=\"class_label\", include_label=False,\n",
    "                                                                     radius=40, node_level=1)\n",
    "\n",
    "# Load the data\n",
    "dataset_constructor.load_data()\n",
    "\n",
    "# Construct the graph\n",
    "dataset = dataset_constructor.construct_graph()\n",
    "\n",
    "\n",
    "total_cells = len(dataset_constructor.adata)\n",
    "print(total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fbeb3-1e4e-4dd8-8d0e-e9ccc4e796eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = split_dataset(dataset,split_percent=(0.2, 0.2, 0.2), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339f2ce-e851-49d8-9cdf-4f835971bc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#scheduler = StepLR(optimizer, step_size=80, gamma=0.1) # learning rate scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4426f-df0f-41ae-af7c-c0289bc76d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_type_labels = np.unique(dataset_constructor.adata.obs[\"class_label\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fcd406-8280-463b-8f70-e982da9ae1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Reshaping the labels to match the required input shape for the encoder\n",
    "cell_type_labels_reshaped = cell_type_labels.reshape(-1, 1)\n",
    "\n",
    "# Creating an instance of OneHotEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the unique class labels\n",
    "label_encoded = encoder.fit_transform(cell_type_labels_reshaped)\n",
    "\n",
    "# Creating a dictionary to map the unique class labels to their one-hot encoded values\n",
    "label_mapping = {label: code for label, code in zip(cell_type_labels, label_encoded)}\n",
    "# Now, label_mapping contains the mapping between unique class labels and one-hot encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc11733-005d-41dc-a53c-a233799d321b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2bec3-ec2b-4c3e-be10-435af194aec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in train_loader:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ea720-766a-4775-90d0-bf696a9507dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Train the model\n",
    "epochs = 100\n",
    "temp = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    model.train()\n",
    "    all_accuracy = []\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(train_loader):\n",
    "        img = data.image[0]\n",
    "        #sub_adata = dataset_constructor.adata[dataset_constructor.adata.obs[\"section\"] == img].copy()\n",
    "        inputs = torch.tensor(data.y, dtype=torch.float)\n",
    "        #print(inputs.shape)\n",
    "        #inputs = inputs[data.mask]\n",
    "        # Convert the cell_type_masked to a flat list of labels\n",
    "        labels = torch.tensor([label_mapping[value] for value in data.cell_type_masked[0]])\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs.to(device), data.edge_index.to(device))\n",
    "        temp.extend(outputs.detach().cpu().tolist())\n",
    "        loss = criterion(outputs.float().cpu(), torch.tensor(labels).long().cpu())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        accuracy = (outputs.argmax(dim=1).cpu() == labels.cpu()).sum().item() / len(labels)\n",
    "        all_accuracy.append(accuracy)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loass: {running_loss / len(train_loader):.3f}, accuracy: {sum(all_accuracy) / len(all_accuracy):.3f}')\n",
    "\n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe90d975-22a9-4495-ab7e-88e8e27edba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def all_elements_same(temp):\n",
    "    if not temp:\n",
    "        return True  # An empty list is considered to have all elements the same\n",
    "    first_element = temp[0]\n",
    "    return all(element == first_element for element in temp)\n",
    "\n",
    "\n",
    "result = all_elements_same(temp)\n",
    "print(result)  # Output: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde820ef-872e-4dc1-967c-7799920c3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch import optim\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Train the model\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    model.train()\n",
    "    all_accuracy = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(train_loader, leave=False):\n",
    "        img = data.image[0]\n",
    "        sub_adata = dataset_constructor.adata[dataset_constructor.adata.obs[\"section\"] == img]\n",
    "        inputs = torch.tensor(sub_adata.X.toarray(), dtype=torch.float).to(device)\n",
    "        # Convert the cell_type_masked to a flat list of labels\n",
    "        labels = torch.tensor([label_mapping[value] for value in data.cell_type_masked[0]], dtype=torch.long).to(device) # Make sure to use long data type\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs, data.edge_index.to(device))\n",
    "\n",
    "        loss = criterion(outputs[data.mask].float(), labels) # Removed the one-hot encoding part\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        accuracy = (outputs.argmax(dim=1) == labels).sum().item() / len(labels)\n",
    "        all_accuracy.append(accuracy)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.3f}, accuracy: {sum(all_accuracy) / len(all_accuracy):.3f}')\n",
    "\n",
    "print('Training finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d55fc-782f-4e5a-a410-104001fd68bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c41924-a549-4702-85de-96ab3020b352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcead8-0fed-4239-b10d-f3448aa63ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f97501-d334-4524-ad2b-3f09b36667e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ml_genetic]",
   "language": "python",
   "name": "conda-env-.conda-ml_genetic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
