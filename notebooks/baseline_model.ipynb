{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:32:16.254306Z",
     "start_time": "2023-07-24T11:32:16.249041Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ouga/home/ag_gagneur/liaoc/.conda/envs/ml_genetic/lib/python3.11/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/data/ouga/home/ag_gagneur/liaoc/.conda/envs/ml_genetic/lib/python3.11/site-packages/spatialdata/__init__.py:9: UserWarning: Geopandas was set to use PyGEOS, changing to shapely 2.0 with:\n",
      "\n",
      "\tgeopandas.options.use_pygeos = True\n",
      "\n",
      "If you intended to use PyGEOS, set the option to False.\n",
      "  _check_geopandas_using_shapely()\n",
      "/data/ouga/home/ag_gagneur/liaoc/.conda/envs/ml_genetic/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nasif12/home_if12/liaoc/spatial_atlas_ssl/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:26:42.046540Z",
     "start_time": "2023-07-24T11:26:41.575309Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read(\"../data/img_119670929.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:28:02.177308Z",
     "start_time": "2023-07-24T11:26:42.047489Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we have the adata object of just a single image\n",
    "sq.gr.spatial_neighbors(adata=adata, radius=1000, key_added=\"adjacency_matrix\", coord_type=\"generic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:28:04.430846Z",
     "start_time": "2023-07-24T11:28:02.180126Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to get k lowest values from each row of a sparse matrix\n",
    "def get_k_lowest_values(matrix, k):\n",
    "    n_rows = matrix.shape[0]\n",
    "    k_lowest_indices = np.empty((n_rows, k), dtype=int)\n",
    "    for i in range(n_rows):\n",
    "        start = matrix.indptr[i]\n",
    "        end = matrix.indptr[i + 1]\n",
    "        row_data = matrix.data[start:end]\n",
    "        row_indices = matrix.indices[start:end]\n",
    "        k_smallest_indices = np.argpartition(row_data, k)[:k]\n",
    "        k_lowest_indices[i] = row_indices[k_smallest_indices]\n",
    "    return k_lowest_indices\n",
    "\n",
    "num_nearest = 10\n",
    "closest_matrix = get_k_lowest_values(adata.obsp['adjacency_matrix_distances'], num_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:33:46.565717Z",
     "start_time": "2023-07-24T11:33:28.349158Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26230/26230 [00:17<00:00, 1533.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# we construct dataset using closest 5 cells\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, cell in tqdm(enumerate(adata.X), total=len(adata)):\n",
    "    y.append(cell.toarray())\n",
    "    five_closest_cells = np.array([adata.X[index].toarray() for index in closest_matrix[i]])\n",
    "    X.append(five_closest_cells.flatten())\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:33:46.571853Z",
     "start_time": "2023-07-24T11:33:46.568833Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26230, 550) (26230, 5500)\n"
     ]
    }
   ],
   "source": [
    "#X = np.concatenate(X)\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:33:46.775690Z",
     "start_time": "2023-07-24T11:33:46.577530Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we use 80% of the data for training and 10% for validation and 10% for testing\n",
    "# Create a custom dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create the dataset and split it into training, validation, and testing sets\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "dataset = MyDataset(X, y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:33:46.814770Z",
     "start_time": "2023-07-24T11:33:46.781120Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T11:33:46.823148Z",
     "start_time": "2023-07-24T11:33:46.819188Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# improve model structure with 2 hidden layer\n",
    "\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_nearest):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim*num_nearest,input_dim*(num_nearest-2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*(num_nearest-2) , input_dim*(num_nearest-4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*(num_nearest-4), output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-24T11:37:13.521914Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.5102, Train R2: 0.1003, Val Loss: 0.4940, Val R2: 0.1316\n",
      "Epoch 2/10, Train Loss: 0.4725, Train R2: 0.1518, Val Loss: 0.4883, Val R2: 0.1406\n",
      "Epoch 3/10, Train Loss: 0.4502, Train R2: 0.1790, Val Loss: 0.4908, Val R2: 0.1400\n",
      "Epoch 4/10, Train Loss: 0.4204, Train R2: 0.2119, Val Loss: 0.4984, Val R2: 0.1338\n",
      "Epoch 5/10, Train Loss: 0.3821, Train R2: 0.2526, Val Loss: 0.5131, Val R2: 0.1218\n",
      "Epoch 6/10, Train Loss: 0.3417, Train R2: 0.2946, Val Loss: 0.5211, Val R2: 0.1165\n",
      "Epoch 7/10, Train Loss: 0.3116, Train R2: 0.3263, Val Loss: 0.5227, Val R2: 0.1147\n",
      "Epoch 8/10, Train Loss: 0.2894, Train R2: 0.3518, Val Loss: 0.5235, Val R2: 0.1126\n",
      "Epoch 9/10, Train Loss: 0.2716, Train R2: 0.3738, Val Loss: 0.5249, Val R2: 0.1079\n",
      "Epoch 10/10, Train Loss: 0.2565, Train R2: 0.3943, Val Loss: 0.5269, Val R2: 0.1046\n"
     ]
    }
   ],
   "source": [
    "# Set device for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an instance of the model and move it to the device\n",
    "input_dim = output_dim = y.shape[1]\n",
    "#output_dim = y.shape[1]\n",
    "\n",
    "model = LinearModel(input_dim, output_dim,num_nearest).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_r2_scores = []\n",
    "val_r2_scores = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Number of epochs to wait for improvement in validation loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        targets_list.append(targets.cpu().numpy())\n",
    "        outputs_list.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "    # Compute and store the average training loss for this epoch\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Calculate R2 score for the training set\n",
    "    train_targets_all = np.concatenate(targets_list)\n",
    "    train_outputs_all = np.concatenate(outputs_list)\n",
    "    train_r2 = r2_score(train_targets_all, train_outputs_all)\n",
    "    train_r2_scores.append(train_r2)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    val_targets_list = []\n",
    "    val_outputs_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the validation loss\n",
    "            val_loss = criterion(outputs, targets)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            val_targets_list.append(targets.cpu().numpy())\n",
    "            val_outputs_list.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "        # Compute and store the average validation loss for this epoch\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Calculate R2 score for the validation set\n",
    "        val_targets_all = np.concatenate(val_targets_list)\n",
    "        val_outputs_all = np.concatenate(val_outputs_list)\n",
    "        val_r2 = r2_score(val_targets_all, val_outputs_all)\n",
    "        val_r2_scores.append(val_r2)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train R2: {train_r2:.4f}, Val Loss: {avg_val_loss:.4f}, Val R2: {val_r2:.4f}\")\n",
    "\n",
    "\n",
    "    # early stopping with patience\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"../models/best_model_1.pt\")\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f\"Early stopping after epoch {epoch + 1}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4793, Test R2: 0.1385\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance on test loader\n",
    "model.load_state_dict(torch.load(\"../models/best_model_1.pt\"))\n",
    "model.eval()\n",
    "test_targets_list = []\n",
    "test_outputs_list = []\n",
    "\n",
    "# loop over test loader and save r2 and loss\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        test_targets_list.append(targets.cpu().numpy())\n",
    "        test_outputs_list.append(outputs.cpu().detach().numpy())\n",
    "\n",
    "test_targets_all = np.concatenate(test_targets_list)\n",
    "test_outputs_all = np.concatenate(test_outputs_list)\n",
    "test_r2 = r2_score(test_targets_all, test_outputs_all)\n",
    "test_loss = criterion(torch.from_numpy(test_outputs_all), torch.from_numpy(test_targets_all)).item()\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test R2: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26230/26230 [00:19<00:00, 1330.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Initialize a list to store the graph data objects\n",
    "data_list = []\n",
    "\n",
    "for i, cell in tqdm(enumerate(adata.X), total=len(adata)):\n",
    "    # Get the gene expression data for the cell and its five closest cells\n",
    "    cell_and_neighbors = np.array([adata.X[index].toarray() for index in closest_matrix[i]])\n",
    "    \n",
    "    # Create a COO-format adjacency matrix for the graph\n",
    "    # Since the graph includes the cell itself and its five closest cells, it has six nodes\n",
    "    # Each node is connected to all other nodes, so there are 6*(6-1)/2 = 15 edges\n",
    "    rows = np.repeat(np.arange(6), 6)\n",
    "    cols = np.tile(np.arange(6), 6)\n",
    "    edge_index = np.stack([rows, cols], axis=0)\n",
    "    \n",
    "    # Create a PyTorch Geometric Data object for the graph\n",
    "    data = Data(x=torch.tensor(cell_and_neighbors, dtype=torch.float), \n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
    "    \n",
    "    # Add the data object to the list\n",
    "    data_list.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26230/26230 [00:20<00:00, 1309.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, cell in tqdm(enumerate(adata.X), total=len(adata)):\n",
    "    # Get the gene expression data for the cell and its five closest cells\n",
    "    cell_and_neighbors = np.array([adata.X[index].toarray() for index in closest_matrix[i]])\n",
    "    \n",
    "    # Create a COO-format adjacency matrix for the graph\n",
    "    # Since the graph includes the cell itself and its five closest cells, it has six nodes\n",
    "    # Each node is connected to all other nodes, so there are 6*(6-1)/2 = 15 edges\n",
    "    rows = np.repeat(np.arange(6), 6)\n",
    "    cols = np.tile(np.arange(6), 6)\n",
    "    \n",
    "    # We only consider lower triangular part to avoid self-loops and duplicate edges\n",
    "    mask = rows < cols\n",
    "    \n",
    "    edge_index = np.stack([rows[mask], cols[mask]], axis=0)\n",
    "    \n",
    "    # Create a PyTorch Geometric Data object for the graph\n",
    "    data = Data(x=torch.tensor(cell_and_neighbors, dtype=torch.float), \n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
    "    \n",
    "    # Add the data object to the list\n",
    "    data_list.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26230/26230 [00:00<00:00, 26948.87it/s]\n"
     ]
    }
   ],
   "source": [
    "target_list = []\n",
    "\n",
    "for i, cell in tqdm(enumerate(adata.X), total=len(adata)):\n",
    "    # Get the gene expression data for the cell itself\n",
    "    target = cell.toarray()\n",
    "    target_list.append(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "train_size = int(0.8 * len(data_list))\n",
    "test_size = len(data_list) - train_size\n",
    "train_data_list = data_list[:train_size]\n",
    "train_target_list = target_list[:train_size]\n",
    "test_data_list = data_list[train_size:]\n",
    "test_target_list = target_list[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m target \u001b[38;5;241m=\u001b[39m train_target_list[i]\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, target)\n\u001b[1;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/ml_genetic/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[27], line 14\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     12\u001b[0m     x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/.conda/envs/ml_genetic/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/ml_genetic/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    208\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/.conda/envs/ml_genetic/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:100\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     99\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[0;32m--> 100\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    102\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/ml_genetic/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:74\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     77\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create an instance of the GCN model\n",
    "model = GCN(input_dim=adata.shape[1], hidden_dim=64, output_dim=1)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    for i in range(len(train_data_list)):\n",
    "        data = train_data_list[i]\n",
    "        target = train_target_list[i]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03221df7c748421daedfe7e7492df240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26230 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create dataset using connectivity matrix of 5 closest cells and expression of 5 closest cells\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, cell in tqdm(enumerate(adata.X), total=len(adata)):\n",
    "    y.append(cell.toarray())\n",
    "    five_closest_cells = np.array([adata.X[index].toarray() for index in closest_matrix[i]])\n",
    "    X.append(five_closest_cells.flatten())\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26230, 550) (26230, 2750)\n"
     ]
    }
   ],
   "source": [
    "# print shape\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
<<<<<<< HEAD
    "import torch\n",
    "from torch_geometric.data import Data\n"
   ]
=======
    "# Initialize a list to store the graph data objects\n",
    "data_list = []\n",
    "\n",
    "for i, cell in tqdm(enumerate(adata.X), total=len(adata)):\n",
    "    # Get the gene expression data for the cell and its five closest cells\n",
    "    cell_and_neighbors = np.array([adata.X[index].toarray() for index in closest_matrix[i]])\n",
    "\n",
    "    # Create a COO-format adjacency matrix for the graph\n",
    "    # Since the graph includes the cell itself and its five closest cells, it has six nodes\n",
    "    # Each node is connected to all other nodes, so there are 6*(6-1)/2 = 15 edges\n",
    "    rows = np.repeat(np.arange(6), 6)\n",
    "    cols = np.tile(np.arange(6), 6)\n",
    "    edge_index = np.stack([rows, cols], axis=0)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object for the graph\n",
    "    data = Data(x=torch.tensor(cell_and_neighbors, dtype=torch.float),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
    "\n",
    "    # Add the data object to the list\n",
    "    data_list.append(data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Initialize a list to store the graph data objects\n",
    "data_list = []\n",
    "\n",
    "for i, cell in tqdm(enumerate(adata.X), total=len(adata)):\n",
    "    # Get the gene expression data for the cell and its five closest cells\n",
    "    cell_and_neighbors = np.array([adata.X[index].toarray() for index in closest_matrix[i]])\n",
    "\n",
    "    # Create a COO-format adjacency matrix for the graph\n",
    "    # Since the graph includes the cell itself and its five closest cells, it has six nodes\n",
    "    # Each node is connected to all other nodes, so there are 6*(6-1)/2 = 15 edges\n",
    "    rows = np.repeat(np.arange(6), 6)\n",
    "    cols = np.tile(np.arange(6), 6)\n",
    "    edge_index = np.stack([rows, cols], axis=0)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object for the graph\n",
    "    data = Data(x=torch.tensor(cell_and_neighbors, dtype=torch.float),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
    "\n",
    "    # Add the data object to the list\n",
    "    data_list.append(data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
>>>>>>> origin/cw
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create dataset using connectivity matrix of 5 closest cells and expression of 5 closest cells\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, cell in tqdm(enumerate(adata.X), total=len(adata)):\n",
    "    y.append(cell.toarray())\n",
    "    five_closest_cells = np.array([adata.X[index].toarray() for index in closest_matrix[i]])\n",
    "    X.append(five_closest_cells.flatten())\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print shape\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#get the connectivity matrix\n",
    "connectivity_matrix = adata.obsp['adjacency_matrix']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ml_genetic]",
   "language": "python",
   "name": "conda-env-.conda-ml_genetic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
