{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T16:42:58.135969Z",
     "start_time": "2023-08-01T16:42:29.937935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52528 of 55530\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import spatialSSL\n",
    "\n",
    "file_path = \"../example_files/img_119670929_1199650932.h5ad\"\n",
    "\n",
    "# Create the dataloader\n",
    "dataset_constructor = spatialSSL.Dataloader.EgoNetDatasetConstructor(file_path=file_path, image_col=\"section\",\n",
    "                                                                     label_col=\"class_label\", include_label=False,\n",
    "                                                                     radius=20, node_level=2)\n",
    "\n",
    "# Load the data\n",
    "dataset_constructor.load_data()\n",
    "\n",
    "# Construct the graph\n",
    "#dataset = dataset_constructor.construct_graph()\n",
    "\n",
    "dataset = torch.load(\"../dataset/dataset.pt\")\n",
    "total_cells = len(dataset_constructor.adata)\n",
    "print(len(dataset), \"of\", total_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "from torch import Tensor, nn\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin1 = nn.Linear(hidden_channels, 20)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.lin1(x).softmax(dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T17:34:55.043160Z",
     "start_time": "2023-08-01T17:34:55.033623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "['MY GABA', 'MY Glut', 'Astro-Epen', 'Oligo', 'P GABA', ..., 'CNU-HYa GABA', 'MB Glut', 'CNU-HYa Glut', 'TH Glut', 'MB Dopa']\nLength: 20\nCategories (20, object): ['Astro-Epen', 'CB GABA', 'CB Glut', 'CNU-HYa GABA', ..., 'P GABA', 'P Glut', 'TH Glut', 'Vascular']"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_constructor.adata.obs.class_label.unique()#.cat.codes.values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T17:35:00.036499Z",
     "start_time": "2023-08-01T17:35:00.017405Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,  3600, 17561])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset:\n",
    "    print(batch.x)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T17:35:00.193391Z",
     "start_time": "2023-08-01T17:35:00.184632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = spatialSSL.Utils.split_dataset(dataset=dataset, split_percent=(0.8, 0.1, 0.1), batch_size = 64)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T17:35:00.762577Z",
     "start_time": "2023-08-01T17:35:00.747599Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([34235, 34489, 34503, 34521, 34530, 34554, 34649, 34664, 34679, 34727,\n",
      "        34732, 34753, 34763, 34764, 34778, 34847, 35176, 35265, 36053, 36103,\n",
      "        36169, 37044, 37189, 37190, 39536, 39620, 39662, 30556, 36370, 37042,\n",
      "        37079, 37201, 48195, 39845, 40944, 44569, 46698, 46710, 47602, 47814,\n",
      "         4937,  6217,  6469,  6473,  6541, 14017, 14999, 16382, 17000, 17633,\n",
      "        17881, 17890, 17986, 19320, 23212, 24141, 24472, 27006, 30318, 30732,\n",
      "        30927, 30928, 39006, 40183, 40457,  5181,  5203,  5738,  6243, 14117,\n",
      "        15352, 15690, 17220, 17236, 17257, 17327, 17339, 17833, 17922, 18457,\n",
      "        23295, 11980, 12434, 24937,   847,  1648,  2971,  7222, 11353, 21332,\n",
      "        21699, 10348, 10514, 11298, 11302, 23570, 36964, 45937, 49323, 54208,\n",
      "        27826, 33314, 33457, 33988, 41861, 41953, 42013, 42501, 42687, 43800,\n",
      "        45205, 45535, 45786, 46014, 46081, 46310, 46580, 46868, 47224, 47707,\n",
      "         7448,  8209,  9729, 12735, 16244, 16996, 17741, 18274, 19092, 19592,\n",
      "        24426, 24427, 27329, 32662, 49769,  4216,  9995, 10687, 24970, 25341,\n",
      "        25342, 25343, 36009, 41066, 41067, 41076, 41191, 41193, 41284, 41906,\n",
      "        42710, 42714, 42817, 43786, 43936, 44119, 46397, 46431, 46508, 46718,\n",
      "        47275, 52350, 52625, 52864, 52970,  1906,  2206,  2386,  2421,  3081,\n",
      "         4031,  5480, 10336, 12002, 20518, 26612, 50269, 41208, 41209, 41388,\n",
      "        42202, 43532, 44322, 46392, 46559, 51869, 51977, 52056, 52761, 26873,\n",
      "        26947, 27073, 28175, 28553, 28748, 28798, 29896, 30073, 35045, 37737,\n",
      "        38036, 40683, 51152, 27152, 32433, 32548, 34044, 34419, 34635, 45094,\n",
      "        45362, 49236, 36343, 36557, 36560, 36843, 36868, 36914, 37130, 44763,\n",
      "        34785, 34824, 34885, 35248, 35249, 35333, 35499, 36423, 36429, 36435,\n",
      "        36849, 36916, 36977, 37049, 37087, 39668, 39671, 54726, 27071, 28061,\n",
      "        28826, 29497, 31699, 34197, 37784, 38236, 38307, 50108, 54287, 54346,\n",
      "        54934, 31769, 31960, 32761, 32793, 32861, 33214, 33312, 33391, 33515,\n",
      "        39210, 41908, 43642, 45682, 45836, 45922, 46249, 46464, 53218, 26576,\n",
      "        37741, 55386, 32019, 32848, 40779, 41228, 41502, 41601, 42029, 42255,\n",
      "        42546, 43777, 44880, 45727, 45731, 45737, 46214, 46292, 46339, 47173,\n",
      "        52016, 53374, 53486, 53898, 54915, 28474, 38690, 39190, 45762, 45887,\n",
      "        48957, 53776,  7588,  7608,  7630,  7832,  8091,  8141,  8647,  8679,\n",
      "         8784, 23522, 23734, 29478, 38399, 39010, 48633, 50833, 51454, 54404,\n",
      "        30258, 30689, 30902, 34010, 48525, 34081, 34235, 34489, 34503, 34507,\n",
      "        34649, 34679, 34847, 34887, 36053, 36103, 36169, 37190, 39446, 39536,\n",
      "        39620, 51246,  7020,  7057,  7376, 12853, 16508, 37726, 37880, 51386,\n",
      "        53800, 54497,  8335, 16206, 16562, 16689, 18894, 19213, 19631, 19632,\n",
      "        24483, 30358, 32917, 42478, 42694, 42980, 43468, 43607, 44410, 49012,\n",
      "        51572, 51955, 52286, 52326, 52329, 52346, 53507, 53510, 55482,  3175,\n",
      "        11077, 23469, 28401, 32428, 34298, 38096, 40222, 50712, 39945, 44845,\n",
      "        45013, 46195, 46197, 47526, 48090, 31736, 33168, 44557, 44749, 45284,\n",
      "        45358, 26758, 26901, 27061, 39855, 40317, 51513,  6571,  6704,  6705,\n",
      "         6734,  6749,  6757,  6967,  7242,  7244,  7548,  7870,  7999,  8685,\n",
      "         8723,  8724,  9473, 11637, 41840, 42625, 42809, 42885, 43621, 43622,\n",
      "        43887, 43894, 43967, 44103, 44228, 44528, 46659, 50570, 52746, 52748,\n",
      "        53468, 54928, 55352,  5057,  5555,  5608,  5696, 15758, 16938, 17038,\n",
      "        17209, 17844, 26446, 28136, 39954,  5003,  6525, 14521, 14642, 16205,\n",
      "        34731, 34877, 35328, 35588, 39627, 39722,  4350,  9974, 10496, 10497,\n",
      "        10706, 20864, 25262, 26034, 27672, 34039, 34984, 51610, 54971, 31527,\n",
      "        39323, 27591, 29327, 30675, 28050, 31795, 32076, 32081, 33222, 33500,\n",
      "        33545, 40903, 42294, 42407, 42448, 42544, 43773, 44096, 45496, 45634,\n",
      "        45650, 46082, 46235, 46923, 49027, 53166, 55341, 29799, 30341, 30346,\n",
      "        31477, 35315, 37712, 34212, 41538, 41570, 41698, 41700, 41702, 41768,\n",
      "        42145, 42380, 42381, 42383, 43341, 43711, 43944, 43945, 44258, 46588,\n",
      "        51871, 52104, 52576, 52783, 53308, 53652, 55350, 35647, 35794, 36339,\n",
      "        36377, 36539, 47581, 47715, 47870, 26443, 26689, 28108, 29090, 29885,\n",
      "        38367, 40001, 40172, 48742, 49812, 33618, 33626, 33740, 33919, 33923,\n",
      "        33944, 33984, 34751, 36323, 36461, 36978, 37084, 37193, 34105, 40938,\n",
      "        41089, 41538, 41697, 42349, 42374, 42376, 43048, 43053, 43172, 43371,\n",
      "        43530, 43531, 43911, 43912, 43941, 43966, 44308, 44309, 44320, 51625,\n",
      "        51919, 52380, 52437, 52488, 52755, 52782, 28161, 28657, 50033, 50469,\n",
      "        29370, 32374, 40200, 53762,  2931,  3194,  4356, 10021, 10075, 21778,\n",
      "        25923,  5892, 11806, 22563, 28178, 28224, 53958, 30866, 33810, 33814,\n",
      "        33993, 35394, 35398, 36114, 38737, 39234, 50430, 27509, 27967, 40523,\n",
      "        42595, 43421, 43886, 49333, 49633, 51619, 52073, 53585, 53890, 55510])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch.x)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T17:35:01.376567Z",
     "start_time": "2023-08-01T17:35:01.343886Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17dbf0eba0124884974837dd67d8494b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fd0508dbed64737ae888bfb6d438a2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.650, accuracy: 0.449\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a17af9140ba142e4b237faa54aa3e91a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.577, accuracy: 0.499\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03532df6f6314557bb2c4ef01094207f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 2.546, accuracy: 0.543\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e08cdb45056492eaa0a7a13078a6fa4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 2.511, accuracy: 0.574\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "709020ea4d2b401fbff7e773c5816e8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 2.505, accuracy: 0.577\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b45106216aa4778a06f930508b3e43d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 2.501, accuracy: 0.580\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ae22307bd9d45ea9d0ada6fdc911df3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 2.496, accuracy: 0.581\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94bd2376d5c84cb8a4cf1bba69f0818a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[72], line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m tqdm(train_loader, leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;66;03m#inputs, _ = data.\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43mdataset_constructor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mtoarray(), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdouble)\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m     23\u001B[0m     labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(dataset_constructor\u001B[38;5;241m.\u001B[39madata[data\u001B[38;5;241m.\u001B[39mx\u001B[38;5;241m.\u001B[39mnumpy()]\u001B[38;5;241m.\u001B[39mobs\u001B[38;5;241m.\u001B[39mclass_label\u001B[38;5;241m.\u001B[39mcat\u001B[38;5;241m.\u001B[39mcodes\u001B[38;5;241m.\u001B[39mvalues)\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mlong()\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m# Zero the parameter gradients\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch import optim\n",
    "\n",
    "net = GCN(in_channels=550, hidden_channels=550, out_channels=550)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "# Train the model\n",
    "epochs = 10\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    net.train()\n",
    "    all_accuracy = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(train_loader, leave=False):\n",
    "        #inputs, _ = data.\n",
    "        input = torch.tensor(dataset_constructor.adata.X[data.x].toarray(), dtype=torch.double).to(device).float()\n",
    "\n",
    "        labels = torch.tensor(dataset_constructor.adata[data.x.numpy()].obs.class_label.cat.codes.values).to(device).long()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(input, data.edge_index)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        accuracy = (outputs.argmax(dim=1) == labels).sum().item() / len(labels)\n",
    "        all_accuracy.append(accuracy)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.3f}, accuracy: {sum(all_accuracy) / len(all_accuracy):.3f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T17:50:56.793176Z",
     "start_time": "2023-08-01T17:35:17.483515Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0093e77e2a134559b91ac29efc28083e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Train Loss: 2.6559, Val Loss: 2.5806 Train Acc: 0.4355, Val Acc: 0.4947\n",
      "Epoch: 2/10, Train Loss: 2.5610, Val Loss: 2.5548 Train Acc: 0.5220, Val Acc: 0.5259\n",
      "Epoch: 3/10, Train Loss: 2.5454, Val Loss: 2.5472 Train Acc: 0.5343, Val Acc: 0.5315\n",
      "Epoch: 4/10, Train Loss: 2.5385, Val Loss: 2.5426 Train Acc: 0.5409, Val Acc: 0.5375\n",
      "Epoch: 5/10, Train Loss: 2.5340, Val Loss: 2.5360 Train Acc: 0.5460, Val Acc: 0.5485\n",
      "Epoch: 6/10, Train Loss: 2.5252, Val Loss: 2.5298 Train Acc: 0.5581, Val Acc: 0.5496\n",
      "Epoch: 7/10, Train Loss: 2.5189, Val Loss: 2.5217 Train Acc: 0.5625, Val Acc: 0.5596\n",
      "Epoch: 8/10, Train Loss: 2.5092, Val Loss: 2.5193 Train Acc: 0.5714, Val Acc: 0.5612\n",
      "Epoch: 9/10, Train Loss: 2.5086, Val Loss: 2.5135 Train Acc: 0.5707, Val Acc: 0.5700\n",
      "Epoch: 10/10, Train Loss: 2.4855, Val Loss: 2.4903 Train Acc: 0.5996, Val Acc: 0.5934\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "net = GCN(in_channels=550, hidden_channels=550, out_channels=550)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "# Train the model\n",
    "# training loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    net.train()\n",
    "\n",
    "    train_accs = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data in train_loader:\n",
    "        #inputs, _ = data.\n",
    "        input = torch.tensor(dataset_constructor.adata.X[data.x].toarray(), dtype=torch.double).to(device).float()\n",
    "\n",
    "        labels = torch.tensor(dataset_constructor.adata[data.x.numpy()].obs.class_label.cat.codes.values).to(device).long()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(input, data.edge_index)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        accuracy = (outputs.argmax(dim=1) == labels).sum().item() / len(labels)\n",
    "        train_accs.append(accuracy)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss = running_loss / len(train_loader)\n",
    "       # Validation\n",
    "    net.eval()\n",
    "    val_accs = []\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for data in val_loader:\n",
    "\n",
    "            input = torch.tensor(dataset_constructor.adata.X[data.x].toarray(), dtype=torch.double).to(device).float()\n",
    "            labels = torch.tensor(dataset_constructor.adata[data.x.numpy()].obs.class_label.cat.codes.values).to(device).long()\n",
    "            outputs = net(input, data.edge_index)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            accuracy = (outputs.argmax(dim=1) == labels).sum().item() / len(labels)\n",
    "            val_accs.append(accuracy)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        #val_accuracy = 100 * correct / total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{epochs}, Train Loss: {running_loss:.4f}, Val Loss: {avg_val_loss:.4f} Train Acc: {mean(train_accs):.4f}, Val Acc: {mean(val_accs):.4f}')\n",
    "\n",
    "\n",
    "\n",
    "    #print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.3f}, accuracy: {sum(all_accuracy) / len(all_accuracy):.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T18:53:01.922707Z",
     "start_time": "2023-08-01T17:58:32.048118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
