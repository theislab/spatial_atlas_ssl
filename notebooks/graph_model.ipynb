{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:16:13.078993Z",
     "start_time": "2023-07-25T09:16:13.072890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "from sklearn.metrics import r2_score\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch_geometric.data import Data   # Create data containers\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:16:15.271509Z",
     "start_time": "2023-07-25T09:16:13.432051Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read(\"../data/img_119670929.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:16:16.610388Z",
     "start_time": "2023-07-25T09:16:15.291428Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean node degree: 3.9\n"
     ]
    }
   ],
   "source": [
    "sq.gr.spatial_neighbors(adata=adata, radius=20, key_added=\"adjacency_matrix\", coord_type=\"generic\")\n",
    "edge_index, edge_weight = from_scipy_sparse_matrix(adata.obsp[\"adjacency_matrix_connectivities\"])\n",
    "x = torch.tensor(adata.X.toarray(), dtype=torch.double)\n",
    "print(f\"mean node degree: {edge_index.shape[1]/len(adata):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:05:32.036001Z",
     "start_time": "2023-07-25T09:05:32.028472Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index)\n",
    "#data\n",
    "#edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:05:32.104671Z",
     "start_time": "2023-07-25T09:05:32.036814Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], size=(2, 0), dtype=torch.int64), None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraph(torch.tensor([0, 10, 33]), edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:05:32.105376Z",
     "start_time": "2023-07-25T09:05:32.051276Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we want to create small subgraph using each node as the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:17:54.336465Z",
     "start_time": "2023-07-25T09:17:53.662441Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a large graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with features to the graph\n",
    "for i, features in enumerate(adata.X.toarray()):\n",
    "    G.add_node(i, features=features)\n",
    "\n",
    "# Add edges to the graph\n",
    "G.add_edges_from(edge_index.t().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:18:00.640450Z",
     "start_time": "2023-07-25T09:17:54.863962Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26230/26230 [00:04<00:00, 6029.69it/s] \n"
     ]
    }
   ],
   "source": [
    "# create subgraphs from each node of G using networkx\n",
    "subgraphs = []\n",
    "for node in tqdm(G.nodes()):\n",
    "    subgraphs.append(nx.ego_graph(G, node, radius = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:18:00.692710Z",
     "start_time": "2023-07-25T09:18:00.657722Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.924590163934426"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean number of nodes per subgraph\n",
    "np.mean([graph.number_of_nodes() for graph in subgraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:18:00.693056Z",
     "start_time": "2023-07-25T09:18:00.665083Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#torch.tensor(list(subgraphs[0].edges)).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:42:38.383496Z",
     "start_time": "2023-07-25T09:42:13.712715Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26230/26230 [00:27<00:00, 947.63it/s] \n"
     ]
    }
   ],
   "source": [
    "# create pytorch geometric dataset from subgraphs\n",
    "#datasss = [Data(x=torch.tensor(graph.nodes(data=\"features\"), dtype=torch.double), edge_index=torch.tensor(list(graph.edges)).t()) for graph in tqdm(subgraphs)]\n",
    "\n",
    "#list(subgraphs[0].features)\n",
    "daata = [from_networkx(graph, group_node_attrs=['features']) for graph in tqdm(subgraphs)]\n",
    "loader = DataLoader(daata, batch_size=32, shuffle=True)\n",
    "#for daat in daata:\n",
    "#loader = DataLoader([from_networkx(graph, group_node_attrs=['features'], dtype=torch.double) for graph in tqdm(subgraphs)], batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "#loader = DataLoader([Data(x=x, edge_index=torch.tensor(list(subgraphs[0].edges)).t()) for graph in subgraphs], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_size = int(0.8 * len(loader.dataset))  # 80% of the data for training\n",
    "val_size = int(0.1 * len(loader.dataset))  # 10% of the data for validation\n",
    "test_size = len(loader.dataset) - train_size - val_size  # The rest for testing\n",
    "\n",
    "train_data, val_data, test_data = random_split(loader.dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders for each set\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:46:49.711321Z",
     "start_time": "2023-07-25T09:46:48.171637Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 146], x=[88, 550], batch=[88], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "for data in loader:\n",
    "    print(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCN, summary\n",
    "\n",
    "#model = GCN(-1, 64, num_layers=2, out_channels=550)\n",
    "#x = torch.randn(100, 128)\n",
    "#edge_index = torch.randint(100, size=(2, 20))\n",
    "\n",
    "#print(summary(model, data.x, data.edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T09:53:04.493328Z",
     "start_time": "2023-07-25T09:53:04.472469Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn, optim, Tensor\n",
    "from torch_geometric.nn import conv\n",
    "\n",
    "\n",
    "# Define the Graph Convolutional Network (GCN) model\n",
    "class GCNClassifier(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, hidden_dim1, output_dim):\n",
    "        super(GCNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            conv.SAGEConv(-1, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            conv.GCNConv(hidden_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        return self.model(x, edge_index)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.linear = nn.Linear(out_channels, 550)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        # x: Node feature matrix of shape [num_nodes, in_channels]\n",
    "        # edge_index: Graph connectivity matrix of shape [2, num_edges]\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        #print(x.shape)\n",
    "        x = self.linear(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 , train loss: 0.5907, train r2: 0.0820 ,  val loss: 0.5621, val r2: 0.1031\n",
      "Epoch 2/50 , train loss: 0.5548, train r2: 0.1098 ,  val loss: 0.5503, val r2: 0.1139\n",
      "Epoch 3/50 , train loss: 0.5490, train r2: 0.1144 ,  val loss: 0.5507, val r2: 0.1130\n",
      "Epoch 4/50 , train loss: 0.5464, train r2: 0.1168 ,  val loss: 0.5476, val r2: 0.1149\n",
      "Epoch 5/50 , train loss: 0.5443, train r2: 0.1186 ,  val loss: 0.5431, val r2: 0.1199\n",
      "Epoch 6/50 , train loss: 0.5435, train r2: 0.1195 ,  val loss: 0.5401, val r2: 0.1229\n",
      "Epoch 7/50 , train loss: 0.5421, train r2: 0.1212 ,  val loss: 0.5463, val r2: 0.1179\n",
      "Epoch 8/50 , train loss: 0.5421, train r2: 0.1214 ,  val loss: 0.5409, val r2: 0.1209\n",
      "Epoch 9/50 , train loss: 0.5403, train r2: 0.1227 ,  val loss: 0.5367, val r2: 0.1250\n",
      "Epoch 10/50 , train loss: 0.5411, train r2: 0.1223 ,  val loss: 0.5437, val r2: 0.1195\n",
      "Epoch 11/50 , train loss: 0.5396, train r2: 0.1236 ,  val loss: 0.5470, val r2: 0.1164\n",
      "Epoch 12/50 , train loss: 0.5393, train r2: 0.1241 ,  val loss: 0.5386, val r2: 0.1230\n",
      "Epoch 13/50 , train loss: 0.5390, train r2: 0.1246 ,  val loss: 0.5375, val r2: 0.1252\n",
      "Epoch 14/50 , train loss: 0.5398, train r2: 0.1241 ,  val loss: 0.5424, val r2: 0.1214\n",
      "Epoch 15/50 , train loss: 0.5385, train r2: 0.1245 ,  val loss: 0.5393, val r2: 0.1239\n",
      "Epoch 16/50 , train loss: 0.5379, train r2: 0.1254 ,  val loss: 0.5400, val r2: 0.1245\n",
      "Epoch 17/50 , train loss: 0.5381, train r2: 0.1257 ,  val loss: 0.5400, val r2: 0.1236\n",
      "Epoch 18/50 , train loss: 0.5393, train r2: 0.1246 ,  val loss: 0.5361, val r2: 0.1273\n",
      "Epoch 19/50 , train loss: 0.5388, train r2: 0.1250 ,  val loss: 0.5373, val r2: 0.1262\n",
      "Epoch 20/50 , train loss: 0.5371, train r2: 0.1265 ,  val loss: 0.5343, val r2: 0.1288\n",
      "Epoch 21/50 , train loss: 0.5369, train r2: 0.1267 ,  val loss: 0.5378, val r2: 0.1267\n",
      "Epoch 22/50 , train loss: 0.5370, train r2: 0.1267 ,  val loss: 0.5363, val r2: 0.1264\n",
      "Epoch 23/50 , train loss: 0.5385, train r2: 0.1255 ,  val loss: 0.5393, val r2: 0.1245\n",
      "Epoch 24/50 , train loss: 0.5375, train r2: 0.1263 ,  val loss: 0.5340, val r2: 0.1277\n",
      "Epoch 25/50 , train loss: 0.5366, train r2: 0.1266 ,  val loss: 0.5386, val r2: 0.1243\n",
      "Epoch 26/50 , train loss: 0.5384, train r2: 0.1256 ,  val loss: 0.5370, val r2: 0.1263\n",
      "Epoch 27/50 , train loss: 0.5366, train r2: 0.1271 ,  val loss: 0.5383, val r2: 0.1246\n",
      "Epoch 28/50 , train loss: 0.5370, train r2: 0.1269 ,  val loss: 0.5400, val r2: 0.1233\n",
      "Epoch 29/50 , train loss: 0.5370, train r2: 0.1267 ,  val loss: 0.5355, val r2: 0.1270\n",
      "Epoch 30/50 , train loss: 0.5379, train r2: 0.1259 ,  val loss: 0.5409, val r2: 0.1246\n",
      "Epoch 31/50 , train loss: 0.5369, train r2: 0.1268 ,  val loss: 0.5335, val r2: 0.1294\n",
      "Epoch 32/50 , train loss: 0.5356, train r2: 0.1278 ,  val loss: 0.5360, val r2: 0.1253\n",
      "Epoch 33/50 , train loss: 0.5366, train r2: 0.1270 ,  val loss: 0.5369, val r2: 0.1259\n",
      "Epoch 34/50 , train loss: 0.5361, train r2: 0.1275 ,  val loss: 0.5392, val r2: 0.1237\n",
      "Epoch 35/50 , train loss: 0.5358, train r2: 0.1275 ,  val loss: 0.5318, val r2: 0.1303\n",
      "Epoch 36/50 , train loss: 0.5364, train r2: 0.1276 ,  val loss: 0.5373, val r2: 0.1264\n",
      "Epoch 37/50 , train loss: 0.5360, train r2: 0.1276 ,  val loss: 0.5394, val r2: 0.1239\n",
      "Epoch 38/50 , train loss: 0.5357, train r2: 0.1278 ,  val loss: 0.5351, val r2: 0.1279\n",
      "Epoch 39/50 , train loss: 0.5361, train r2: 0.1273 ,  val loss: 0.5356, val r2: 0.1269\n",
      "Epoch 40/50 , train loss: 0.5369, train r2: 0.1267 ,  val loss: 0.5344, val r2: 0.1293\n",
      "Epoch 41/50 , train loss: 0.5350, train r2: 0.1284 ,  val loss: 0.5343, val r2: 0.1271\n",
      "Epoch 42/50 , train loss: 0.5358, train r2: 0.1282 ,  val loss: 0.5342, val r2: 0.1285\n",
      "Epoch 43/50 , train loss: 0.5364, train r2: 0.1274 ,  val loss: 0.5374, val r2: 0.1257\n",
      "Epoch 44/50 , train loss: 0.5356, train r2: 0.1279 ,  val loss: 0.5373, val r2: 0.1254\n",
      "Epoch 45/50 , train loss: 0.5360, train r2: 0.1276 ,  val loss: 0.5322, val r2: 0.1297\n",
      "Epoch 46/50 , train loss: 0.5359, train r2: 0.1280 ,  val loss: 0.5316, val r2: 0.1312\n",
      "Epoch 47/50 , train loss: 0.5354, train r2: 0.1289 ,  val loss: 0.5358, val r2: 0.1261\n",
      "Epoch 48/50 , train loss: 0.5358, train r2: 0.1275 ,  val loss: 0.5328, val r2: 0.1297\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Set device for training, macbook\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an instance of the model and move it to the device\n",
    "\n",
    "output_dim = 550\n",
    "\n",
    "# Create the model\n",
    "model = GCN(-1, 64, output_dim).to(device)\n",
    "\n",
    "#GCNClassifier(hidden_dim=100, hidden_dim1=100, output_dim=550).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "# store losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# store r2 scores\n",
    "train_r2_scores = []\n",
    "val_r2_scores = []\n",
    "\n",
    "best_val_loss = float('inf') # Set initial best validation loss to infinity\n",
    "patience = 5                # Number of epochs to wait for improvement in validation loss\n",
    "epochs_no_improve = 0        # Number of epochs with no improvement in validation loss\n",
    "best_epoch = 0               # Epoch at which we get the best validation loss\n",
    "\n",
    "# epoch training times\n",
    "epoch_times = []\n",
    "#start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_targets_list = []\n",
    "    train_outputs_list = []\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        num_nodes = data.x.shape[0]\n",
    "        num_nodes_to_mask = int(0.2 * num_nodes)\n",
    "        nodes_to_mask = random.sample(range(num_nodes), num_nodes_to_mask)\n",
    "        mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        mask[nodes_to_mask] = True\n",
    "        masked_node_features = data.x.float() * mask.unsqueeze(-1).float().to(device)\n",
    "\n",
    "\n",
    "        outputs = model(masked_node_features, data.edge_index.long())\n",
    "        loss = criterion(outputs, data.x.float())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure train loss and r2 score\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        targets_list.append(data.x.float())\n",
    "        outputs_list.append(outputs)\n",
    "\n",
    "    #measure and print r2 and train loss\n",
    "    train_loss = total_loss / len(loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    train_r2 = r2_score(torch.cat(targets_list).cpu().detach().numpy(), torch.cat(outputs_list).cpu().detach().numpy())\n",
    "    train_r2_scores.append(train_r2)\n",
    "\n",
    "        # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    val_targets_list = []\n",
    "    val_outputs_list = []\n",
    "\n",
    "    for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        num_nodes = data.x.shape[0]\n",
    "        num_nodes_to_mask = int(0.2 * num_nodes)\n",
    "        nodes_to_mask = random.sample(range(num_nodes), num_nodes_to_mask)\n",
    "        mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        mask[nodes_to_mask] = True\n",
    "        masked_node_features = data.x.float() * mask.unsqueeze(-1).float().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(masked_node_features, data.edge_index.long())\n",
    "            loss = criterion(outputs, data.x.float())\n",
    "        total_val_loss += loss.item() * data.num_graphs\n",
    "        val_targets_list.append(data.x.float())\n",
    "        val_outputs_list.append(outputs)\n",
    "\n",
    "    # Measure and print validation loss and R2\n",
    "    val_loss = total_val_loss / len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    val_r2 = r2_score(torch.cat(val_targets_list).cpu().detach().numpy(), torch.cat(val_outputs_list).cpu().detach().numpy())\n",
    "    val_r2_scores.append(val_r2)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} , train loss: {train_loss:.4f}, train r2: {train_r2:.4f} ,  val loss: {val_loss:.4f}, val r2: {val_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5162, test r2: 0.1203\n"
     ]
    }
   ],
   "source": [
    "# Testing phase\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "test_targets_list = []\n",
    "test_outputs_list = []\n",
    "\n",
    "for data in test_loader:\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data.x.float(), data.edge_index.long())\n",
    "        loss = criterion(outputs, data.x.float())\n",
    "    total_test_loss += loss.item() * data.num_graphs\n",
    "    test_targets_list.append(data.x.float())\n",
    "    test_outputs_list.append(outputs)\n",
    "\n",
    "# Measure and print test loss and R2\n",
    "test_loss = total_test_loss / len(test_loader.dataset)\n",
    "test_r2 = r2_score(torch.cat(test_targets_list).cpu().detach().numpy(), torch.cat(test_outputs_list).cpu().detach().numpy())\n",
    "print(f\"Test loss: {test_loss:.4f}, test r2: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ml_genetic]",
   "language": "python",
   "name": "conda-env-.conda-ml_genetic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
